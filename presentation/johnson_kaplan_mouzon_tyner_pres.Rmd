---
title: "Reversible Jump MCMC"
author: "Maggie Johnson, Andee Kaplan, Ian Mouzon, and Samantha Tyner"
date: "April 10, 2015"
output: 
  ioslides_presentation:
    css: css/style.css
bibliography: ../paper/bibliography.bib
nocite: | 
  @green2009reversible
---

# Problem Statement | Trans-dimensional problems

## Primary Goal

To solve problems where
*"...the number of things you don’t know is one of the things you don’t know!"*

![idk](images/idk_idk.jpg)

# What is RJMCMC?

## RJMCMC makes you wanna...

![http://giphy.com/gifs/jump-NupHKw9kFaaEE](images/kris_kross.gif)

## Reversible Chain

  - Definition
  - Animation
  - Detailed balance condition

## Algorithm
This may be moved to paper only, depending on time/detail required

# Example

## Poisson/Negative Binomial Model

# Challenges for implementation

## Choosing priors

## Tuning

## Diagnostics

# Beyond...

## Extensions to...

  - Adaptive RJMCMC [@hastie2005towards]
  - Interacting Sequential MCMC [@jasra2008interacting]
  - Simulated Annealing extended for trans-dimensionsal problems [@geman1984stochastic]

<div class="notes">
  - Efficiency gains - adaptive sampling. Idea: proposal mechanisms may be allowed to depend on past realizations of the chain, not just current state without invalidating ergodicity of process. Optimal location and scaling of proposal can be determined during run, eliminating tuning.
  - ISMC - Several sequential MC samplers run in parallel, separate subspaces. For each sampler at time $t < T$, particles updated using (reversible) MCMC moves. When a predetermined time $t^* < T$ is reached, the separate samplers are combined into a single sampler moving across all models.
  - Simulated annealing where an optimal model may need to be determined. I.e., function $f$ quantity to minimize with some penalization terms. Trans-dimensional simulated annealing proceeds by using reversible jump moves to construct a Markov chain with appropriate invariant dsn. Once equilibrium achieved, temperature is decreased and new phase is started from the state the chain ended in.
</div>

## Alternatives to... | for trans-dimensional problems

  - Jump diffusion [@grenander1994representations]
  - Marked point processes [@stephens2000bayesian]
  - Product Space approach [@carlin1995bayesian]
  
<div class="notes">
   - Jump diffusion - between model jumps and within model diffusion according to Langevin stochastic differential equation - time evolution of a subset of the degrees of freedom
   - Marked point - variable number of items regarded as marked points (component pairs), borrows from birth-and-death simulation idea (integrating out latent variables)
   - Product space - work on a more general state space, where the simulation keeps track of all $\theta_k$ instead of the current one, then the state vector is of fixed dimension avoiding trans-dimensional problem
</div>

# Appendix

## Development of $\alpha$ {#appendix}

**Metropolis-Hastings on a general state space**

To construct a Markov chain on a state space $\mathcal{X}$ with invariant distribution $\pi$. We will only consider reversible chains, so the transition kernel $P$ satisfies the detailed balance condition

$$
\int\limits_{(x, x') \in A \times B} \pi(dx)P(x, dx') = \int\limits_{(x, x') \in A \times B} \pi(dx')P(x', dx)
$$

for all Borel sets $A,B \subset \mathcal{X}$. We make a transition by frawing a candidate new state $x'$ from the proposal measure $q(x, dx')$ and accepting it with probability $\alpha(x, x')$. We we reject, we stay in the current state so that $P(x, dx')$ has an element at $x$. This constributes $\int_{A\cap B} P(x, \{x\}) \pi(dx)$ to each side of the balance equation; subtracting leaves

$$
\int\limits_{(x, x') \in A \times B} \pi(dx)q(x, dx')\alpha(x, x') = \int\limits_{(x, x') \in A \times B} \pi(dx')q(x', dx)\alpha(x', x)
$$

Now $ \pi(dx)q(x, dx')$ is dominated by a symmetric measure $\mu$ on $\mathcal{X} \times \mathcal{X}$ and let its density wrt $\mu$ be denoted $f$. Then the above equality becomes

$$
\int\limits_{(x, x') \in A \times B} \alpha(x, x')f(x, x')\mu(dx, dx') = \int\limits_{(x, x') \in A \times B} \alpha(x', x)f(x', x)\mu(dx', dx)
$$

and by the summetry of $\mu$, this is satisfied for all Borel $A,B$ if

$$
\alpha(x, x') = \min\left\{1, \frac{f(x', x)}{f(x, x')}\right\} =  \min\left\{1, \frac{\pi(dx')q(x', dx)}{\pi(dx)q(x, dx')}\right\}
$$

## Development of $\alpha$ Cont'd {#appendix}

**Constructive representation in terms of random numbers**

Let $\mathcal{X} \subset \mathbb{R}^d$ and suppose $\pi$ has a density wrt to the $d$-dimensional Lebesgue measure (also denoted $\pi$). At the current state $x$, we generate $r$ random numbers $u$ from a known joint density $g$ and then form the proposed new state as a deterministic function of the current state and the random numbers so that $x' = h(x, u)$. Then the second equality on the previous slide can be written

$$
\int\limits_{(x, x') \in A \times B} \pi(x) g(u) \alpha(x, x') dx du = \int\limits_{(x, x') \in A \times B} \pi(x') g(u') \alpha(x', x) dx' du'.
$$

Where the reverse transition from $x'$ to $x$ is made with the aid of random numbers $u' \sim g'$ giving $x = \mathcal{H}(x', u')$ and this transformation from $(x, u)$ to $(x', u')$ is a diffeomorphism. Then the $(d + r)$-dimensional integral equality holds if

$$
\pi(x)g(u)\alpha(x, x') = \pi(x') g(u') \alpha(x', x) \left|\frac{\partial(x', u')}{\partial(x,u)}\right|.
$$

Then, a valid choice for $\alpha$ is 

$$
\alpha(x, x') = \min\left\{1, \frac{\pi(x')g'(u')}{\pi(x)g(u)} \left|\frac{\partial(x', u')}{\partial(x,u)}\right|\right\}
$$

[@green2003trans]

## References {#appendix}






